| distributed init (rank 0): env://
| distributed init (rank 1): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
gpua001:3089662:3089662 [0] NCCL INFO Bootstrap: Using eth1:172.28.23.1<0>
gpua001:3089662:3089662 [0] NCCL INFO cudaDriverVersion 12040
gpua001:3089662:3089662 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
gpua001:3089662:3089662 [0] NCCL INFO Comm config Blocking set to 1
gpua001:3089663:3089663 [1] NCCL INFO cudaDriverVersion 12040
gpua001:3089663:3089663 [1] NCCL INFO Bootstrap: Using eth1:172.28.23.1<0>
gpua001:3089663:3089663 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
gpua001:3089665:3089665 [3] NCCL INFO cudaDriverVersion 12040
gpua001:3089663:3089663 [1] NCCL INFO Comm config Blocking set to 1
gpua001:3089665:3089665 [3] NCCL INFO Bootstrap: Using eth1:172.28.23.1<0>
gpua001:3089665:3089665 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
gpua001:3089665:3089665 [3] NCCL INFO Comm config Blocking set to 1
gpua001:3089664:3089664 [2] NCCL INFO cudaDriverVersion 12040
gpua001:3089664:3089664 [2] NCCL INFO Bootstrap: Using eth1:172.28.23.1<0>
gpua001:3089664:3089664 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
gpua001:3089664:3089664 [2] NCCL INFO Comm config Blocking set to 1
gpua001:3089662:3089704 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
gpua001:3089665:3089706 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
gpua001:3089664:3089707 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
gpua001:3089663:3089705 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
gpua001:3089665:3089706 [3] NCCL INFO NET/IB : No device found.
gpua001:3089664:3089707 [2] NCCL INFO NET/IB : No device found.
gpua001:3089662:3089704 [0] NCCL INFO NET/IB : No device found.
gpua001:3089663:3089705 [1] NCCL INFO NET/IB : No device found.
gpua001:3089665:3089706 [3] NCCL INFO NET/IB : Using [RO]; OOB eth1:172.28.23.1<0>
gpua001:3089664:3089707 [2] NCCL INFO NET/IB : Using [RO]; OOB eth1:172.28.23.1<0>
gpua001:3089662:3089704 [0] NCCL INFO NET/IB : Using [RO]; OOB eth1:172.28.23.1<0>
gpua001:3089663:3089705 [1] NCCL INFO NET/IB : Using [RO]; OOB eth1:172.28.23.1<0>
gpua001:3089663:3089705 [1] NCCL INFO NET/Socket : Using [0]eth1:172.28.23.1<0> [1]hsn0:172.28.86.1<0> [2]hsn0.561:141.142.254.1<0>
gpua001:3089662:3089704 [0] NCCL INFO NET/Socket : Using [0]eth1:172.28.23.1<0> [1]hsn0:172.28.86.1<0> [2]hsn0.561:141.142.254.1<0>
gpua001:3089665:3089706 [3] NCCL INFO NET/Socket : Using [0]eth1:172.28.23.1<0> [1]hsn0:172.28.86.1<0> [2]hsn0.561:141.142.254.1<0>
gpua001:3089664:3089707 [2] NCCL INFO NET/Socket : Using [0]eth1:172.28.23.1<0> [1]hsn0:172.28.86.1<0> [2]hsn0.561:141.142.254.1<0>
gpua001:3089663:3089705 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
gpua001:3089664:3089707 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
gpua001:3089662:3089704 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
gpua001:3089663:3089705 [1] NCCL INFO Using network Socket
gpua001:3089665:3089706 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
gpua001:3089664:3089707 [2] NCCL INFO Using network Socket
gpua001:3089662:3089704 [0] NCCL INFO Using network Socket
gpua001:3089665:3089706 [3] NCCL INFO Using network Socket
gpua001:3089663:3089705 [1] NCCL INFO ncclCommInitRankConfig comm 0xb12cfd0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 46000 commId 0x7505032aeae7505c - Init START
gpua001:3089662:3089704 [0] NCCL INFO ncclCommInitRankConfig comm 0xb736be0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 7000 commId 0x7505032aeae7505c - Init START
gpua001:3089665:3089706 [3] NCCL INFO ncclCommInitRankConfig comm 0xae90c00 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c7000 commId 0x7505032aeae7505c - Init START
gpua001:3089664:3089707 [2] NCCL INFO ncclCommInitRankConfig comm 0xb067340 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 85000 commId 0x7505032aeae7505c - Init START
gpua001:3089662:3089704 [0] NCCL INFO RAS client listening socket at ::1<28028>
gpua001:3089663:3089705 [1] NCCL INFO RAS client listening socket at ::1<28028>
gpua001:3089664:3089707 [2] NCCL INFO RAS client listening socket at ::1<28028>
gpua001:3089665:3089706 [3] NCCL INFO RAS client listening socket at ::1<28028>
gpua001:3089663:3089705 [1] NCCL INFO Bootstrap timings total 0.001678 (create 0.000038, send 0.000165, recv 0.000980, ring 0.000146, delay 0.000001)
gpua001:3089662:3089704 [0] NCCL INFO Bootstrap timings total 0.001030 (create 0.000025, send 0.000109, recv 0.000127, ring 0.000291, delay 0.000000)
gpua001:3089665:3089706 [3] NCCL INFO Bootstrap timings total 0.000957 (create 0.000032, send 0.000105, recv 0.000193, ring 0.000066, delay 0.000000)
gpua001:3089664:3089707 [2] NCCL INFO Bootstrap timings total 0.000965 (create 0.000029, send 0.000105, recv 0.000408, ring 0.000067, delay 0.000000)
gpua001:3089662:3089704 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,00000000
gpua001:3089662:3089704 [0] NCCL INFO NVLS multicast support is not available on dev 0
gpua001:3089664:3089707 [2] NCCL INFO Setting affinity for GPU 2 to ffff0000
gpua001:3089664:3089707 [2] NCCL INFO NVLS multicast support is not available on dev 2
gpua001:3089665:3089706 [3] NCCL INFO Setting affinity for GPU 3 to ffff
gpua001:3089665:3089706 [3] NCCL INFO NVLS multicast support is not available on dev 3
gpua001:3089663:3089705 [1] NCCL INFO Setting affinity for GPU 1 to ffff,00000000
gpua001:3089663:3089705 [1] NCCL INFO NVLS multicast support is not available on dev 1
gpua001:3089662:3089704 [0] NCCL INFO comm 0xb736be0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
gpua001:3089665:3089706 [3] NCCL INFO comm 0xae90c00 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
gpua001:3089664:3089707 [2] NCCL INFO comm 0xb067340 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
gpua001:3089663:3089705 [1] NCCL INFO comm 0xb12cfd0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
gpua001:3089662:3089704 [0] NCCL INFO Channel 00/24 : 0 1 3 2
gpua001:3089662:3089704 [0] NCCL INFO Channel 01/24 : 0 1 2 3
gpua001:3089662:3089704 [0] NCCL INFO Channel 02/24 : 0 3 2 1
gpua001:3089662:3089704 [0] NCCL INFO Channel 03/24 : 0 3 1 2
gpua001:3089662:3089704 [0] NCCL INFO Channel 04/24 : 0 2 1 3
gpua001:3089662:3089704 [0] NCCL INFO Channel 05/24 : 0 2 3 1
gpua001:3089662:3089704 [0] NCCL INFO Channel 06/24 : 0 1 3 2
gpua001:3089662:3089704 [0] NCCL INFO Channel 07/24 : 0 1 2 3
gpua001:3089662:3089704 [0] NCCL INFO Channel 08/24 : 0 3 2 1
gpua001:3089664:3089707 [2] NCCL INFO Trees [0] -1/-1/-1->2->3 [1] -1/-1/-1->2->3 [2] -1/-1/-1->2->3 [3] -1/-1/-1->2->3 [4] -1/-1/-1->2->1 [5] -1/-1/-1->2->1 [6] -1/-1/-1->2->1 [7] -1/-1/-1->2->1 [8] 3/-1/-1->2->0 [9] 3/-1/-1->2->0 [10] 3/-1/-1->2->0 [11] 3/-1/-1->2->0 [12] -1/-1/-1->2->3 [13] -1/-1/-1->2->3 [14] -1/-1/-1->2->3 [15] -1/-1/-1->2->3 [16] -1/-1/-1->2->1 [17] -1/-1/-1->2->1 [18] -1/-1/-1->2->1 [19] -1/-1/-1->2->1 [20] 3/-1/-1->2->0 [21] 3/-1/-1->2->0 [22] 3/-1/-1->2->0 [23] 3/-1/-1->2->0
gpua001:3089665:3089706 [3] NCCL INFO Trees [0] 2/-1/-1->3->1 [1] 2/-1/-1->3->1 [2] 2/-1/-1->3->1 [3] 2/-1/-1->3->1 [4] 1/-1/-1->3->0 [5] 1/-1/-1->3->0 [6] 1/-1/-1->3->0 [7] 1/-1/-1->3->0 [8] -1/-1/-1->3->2 [9] -1/-1/-1->3->2 [10] -1/-1/-1->3->2 [11] -1/-1/-1->3->2 [12] 2/-1/-1->3->1 [13] 2/-1/-1->3->1 [14] 2/-1/-1->3->1 [15] 2/-1/-1->3->1 [16] 1/-1/-1->3->0 [17] 1/-1/-1->3->0 [18] 1/-1/-1->3->0 [19] 1/-1/-1->3->0 [20] -1/-1/-1->3->2 [21] -1/-1/-1->3->2 [22] -1/-1/-1->3->2 [23] -1/-1/-1->3->2
gpua001:3089662:3089704 [0] NCCL INFO Channel 09/24 : 0 3 1 2
gpua001:3089665:3089706 [3] NCCL INFO P2P Chunksize set to 524288
gpua001:3089664:3089707 [2] NCCL INFO P2P Chunksize set to 524288
gpua001:3089663:3089705 [1] NCCL INFO Trees [0] 3/-1/-1->1->0 [1] 3/-1/-1->1->0 [2] 3/-1/-1->1->0 [3] 3/-1/-1->1->0 [4] 2/-1/-1->1->3 [5] 2/-1/-1->1->3 [6] 2/-1/-1->1->3 [7] 2/-1/-1->1->3 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 3/-1/-1->1->0 [13] 3/-1/-1->1->0 [14] 3/-1/-1->1->0 [15] 3/-1/-1->1->0 [16] 2/-1/-1->1->3 [17] 2/-1/-1->1->3 [18] 2/-1/-1->1->3 [19] 2/-1/-1->1->3 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
gpua001:3089662:3089704 [0] NCCL INFO Channel 10/24 : 0 2 1 3
gpua001:3089663:3089705 [1] NCCL INFO P2P Chunksize set to 524288
gpua001:3089662:3089704 [0] NCCL INFO Channel 11/24 : 0 2 3 1
gpua001:3089662:3089704 [0] NCCL INFO Channel 12/24 : 0 1 3 2
gpua001:3089662:3089704 [0] NCCL INFO Channel 13/24 : 0 1 2 3
gpua001:3089662:3089704 [0] NCCL INFO Channel 14/24 : 0 3 2 1
gpua001:3089662:3089704 [0] NCCL INFO Channel 15/24 : 0 3 1 2
gpua001:3089662:3089704 [0] NCCL INFO Channel 16/24 : 0 2 1 3
gpua001:3089662:3089704 [0] NCCL INFO Channel 17/24 : 0 2 3 1
gpua001:3089662:3089704 [0] NCCL INFO Channel 18/24 : 0 1 3 2
gpua001:3089662:3089704 [0] NCCL INFO Channel 19/24 : 0 1 2 3
gpua001:3089662:3089704 [0] NCCL INFO Channel 20/24 : 0 3 2 1
gpua001:3089662:3089704 [0] NCCL INFO Channel 21/24 : 0 3 1 2
gpua001:3089662:3089704 [0] NCCL INFO Channel 22/24 : 0 2 1 3
gpua001:3089662:3089704 [0] NCCL INFO Channel 23/24 : 0 2 3 1
gpua001:3089662:3089704 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 3/-1/-1->0->-1 [5] 3/-1/-1->0->-1 [6] 3/-1/-1->0->-1 [7] 3/-1/-1->0->-1 [8] 2/-1/-1->0->1 [9] 2/-1/-1->0->1 [10] 2/-1/-1->0->1 [11] 2/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 3/-1/-1->0->-1 [17] 3/-1/-1->0->-1 [18] 3/-1/-1->0->-1 [19] 3/-1/-1->0->-1 [20] 2/-1/-1->0->1 [21] 2/-1/-1->0->1 [22] 2/-1/-1->0->1 [23] 2/-1/-1->0->1
gpua001:3089662:3089704 [0] NCCL INFO P2P Chunksize set to 524288
gpua001:3089662:3089704 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
gpua001:3089665:3089712 [3] NCCL INFO [Proxy Service] Device 3 CPU core 9
gpua001:3089665:3089716 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 2
gpua001:3089662:3089717 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 50
gpua001:3089662:3089714 [0] NCCL INFO [Proxy Service] Device 0 CPU core 62
gpua001:3089663:3089718 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 47
gpua001:3089663:3089713 [1] NCCL INFO [Proxy Service] Device 1 CPU core 40
gpua001:3089664:3089719 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 18
gpua001:3089664:3089715 [2] NCCL INFO [Proxy Service] Device 2 CPU core 28
gpua001:3089662:3089704 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gpua001:3089662:3089704 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
gpua001:3089665:3089706 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gpua001:3089665:3089706 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
gpua001:3089663:3089705 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gpua001:3089663:3089705 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
gpua001:3089664:3089707 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gpua001:3089664:3089707 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
gpua001:3089662:3089704 [0] NCCL INFO CC Off, workFifoBytes 1048576
gpua001:3089665:3089706 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
gpua001:3089665:3089706 [3] NCCL INFO ncclCommInitRankConfig comm 0xae90c00 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c7000 commId 0x7505032aeae7505c - Init COMPLETE
gpua001:3089664:3089707 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
gpua001:3089663:3089705 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
gpua001:3089665:3089706 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.44 (kernels 0.17, alloc 0.08, bootstrap 0.00, allgathers 0.00, topo 0.15, graphs 0.00, connections 0.02, rest 0.01)
gpua001:3089662:3089704 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
gpua001:3089664:3089707 [2] NCCL INFO ncclCommInitRankConfig comm 0xb067340 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 85000 commId 0x7505032aeae7505c - Init COMPLETE
gpua001:3089662:3089704 [0] NCCL INFO ncclCommInitRankConfig comm 0xb736be0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 7000 commId 0x7505032aeae7505c - Init COMPLETE
gpua001:3089663:3089705 [1] NCCL INFO ncclCommInitRankConfig comm 0xb12cfd0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 46000 commId 0x7505032aeae7505c - Init COMPLETE
gpua001:3089664:3089707 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.44 (kernels 0.17, alloc 0.08, bootstrap 0.00, allgathers 0.00, topo 0.15, graphs 0.00, connections 0.02, rest 0.01)
gpua001:3089662:3089704 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.46 (kernels 0.19, alloc 0.08, bootstrap 0.00, allgathers 0.00, topo 0.15, graphs 0.00, connections 0.02, rest 0.01)
gpua001:3089663:3089705 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.45 (kernels 0.18, alloc 0.08, bootstrap 0.00, allgathers 0.00, topo 0.15, graphs 0.00, connections 0.02, rest 0.01)
gpua001:3089665:3089720 [3] NCCL INFO Channel 01/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gpua001:3089662:3089722 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gpua001:3089664:3089723 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gpua001:3089663:3089721 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gpua001:3089665:3089720 [3] NCCL INFO Channel 04/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gpua001:3089662:3089722 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gpua001:3089664:3089723 [2] NCCL INFO Channel 05/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gpua001:3089663:3089721 [1] NCCL INFO Channel 03/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gpua001:3089665:3089720 [3] NCCL INFO Channel 07/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gpua001:3089662:3089722 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gpua001:3089664:3089723 [2] NCCL INFO Channel 07/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gpua001:3089663:3089721 [1] NCCL INFO Channel 07/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gpua001:3089665:3089720 [3] NCCL INFO Channel 10/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gpua001:3089662:3089722 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gpua001:3089664:3089723 [2] NCCL INFO Channel 11/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gpua001:3089663:3089721 [1] NCCL INFO Channel 09/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gpua001:3089665:3089720 [3] NCCL INFO Channel 13/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gpua001:3089662:3089722 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gpua001:3089664:3089723 [2] NCCL INFO Channel 13/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gpua001:3089663:3089721 [1] NCCL INFO Channel 13/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gpua001:3089665:3089720 [3] NCCL INFO Channel 16/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gpua001:3089662:3089722 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gpua001:3089664:3089723 [2] NCCL INFO Channel 17/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gpua001:3089663:3089721 [1] NCCL INFO Channel 15/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gpua001:3089665:3089720 [3] NCCL INFO Channel 19/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gpua001:3089662:3089722 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gpua001:3089664:3089723 [2] NCCL INFO Channel 19/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gpua001:3089663:3089721 [1] NCCL INFO Channel 19/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gpua001:3089665:3089720 [3] NCCL INFO Channel 22/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gpua001:3089662:3089722 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gpua001:3089664:3089723 [2] NCCL INFO Channel 23/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gpua001:3089663:3089721 [1] NCCL INFO Channel 21/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gpua001:3089662:3089722 [0] NCCL INFO Channel 04/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gpua001:3089665:3089720 [3] NCCL INFO Channel 03/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gpua001:3089664:3089723 [2] NCCL INFO Channel 00/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gpua001:3089663:3089721 [1] NCCL INFO Channel 00/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gpua001:3089662:3089722 [0] NCCL INFO Channel 05/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gpua001:3089665:3089720 [3] NCCL INFO Channel 05/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gpua001:3089664:3089723 [2] NCCL INFO Channel 03/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gpua001:3089663:3089721 [1] NCCL INFO Channel 04/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gpua001:3089662:3089722 [0] NCCL INFO Channel 10/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gpua001:3089665:3089720 [3] NCCL INFO Channel 09/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gpua001:3089664:3089723 [2] NCCL INFO Channel 06/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gpua001:3089663:3089721 [1] NCCL INFO Channel 06/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gpua001:3089662:3089722 [0] NCCL INFO Channel 11/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gpua001:3089665:3089720 [3] NCCL INFO Channel 11/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gpua001:3089664:3089723 [2] NCCL INFO Channel 09/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gpua001:3089663:3089721 [1] NCCL INFO Channel 10/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gpua001:3089662:3089722 [0] NCCL INFO Channel 16/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gpua001:3089665:3089720 [3] NCCL INFO Channel 15/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gpua001:3089664:3089723 [2] NCCL INFO Channel 12/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gpua001:3089663:3089721 [1] NCCL INFO Channel 12/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gpua001:3089662:3089722 [0] NCCL INFO Channel 17/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gpua001:3089665:3089720 [3] NCCL INFO Channel 17/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gpua001:3089664:3089723 [2] NCCL INFO Channel 15/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gpua001:3089663:3089721 [1] NCCL INFO Channel 16/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gpua001:3089662:3089722 [0] NCCL INFO Channel 22/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gpua001:3089665:3089720 [3] NCCL INFO Channel 21/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gpua001:3089664:3089723 [2] NCCL INFO Channel 18/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gpua001:3089663:3089721 [1] NCCL INFO Channel 18/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gpua001:3089662:3089722 [0] NCCL INFO Channel 23/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gpua001:3089665:3089720 [3] NCCL INFO Channel 23/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gpua001:3089664:3089723 [2] NCCL INFO Channel 21/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gpua001:3089663:3089721 [1] NCCL INFO Channel 22/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gpua001:3089662:3089722 [0] NCCL INFO Channel 02/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gpua001:3089664:3089723 [2] NCCL INFO Channel 02/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gpua001:3089663:3089721 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gpua001:3089665:3089720 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gpua001:3089662:3089722 [0] NCCL INFO Channel 03/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gpua001:3089664:3089723 [2] NCCL INFO Channel 04/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gpua001:3089663:3089721 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gpua001:3089665:3089720 [3] NCCL INFO Channel 02/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gpua001:3089662:3089722 [0] NCCL INFO Channel 08/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gpua001:3089664:3089723 [2] NCCL INFO Channel 08/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gpua001:3089663:3089721 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gpua001:3089665:3089720 [3] NCCL INFO Channel 06/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gpua001:3089662:3089722 [0] NCCL INFO Channel 09/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gpua001:3089664:3089723 [2] NCCL INFO Channel 10/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gpua001:3089663:3089721 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gpua001:3089665:3089720 [3] NCCL INFO Channel 08/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gpua001:3089662:3089722 [0] NCCL INFO Channel 14/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gpua001:3089664:3089723 [2] NCCL INFO Channel 14/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gpua001:3089663:3089721 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gpua001:3089665:3089720 [3] NCCL INFO Channel 12/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gpua001:3089662:3089722 [0] NCCL INFO Channel 15/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gpua001:3089664:3089723 [2] NCCL INFO Channel 16/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gpua001:3089663:3089721 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gpua001:3089665:3089720 [3] NCCL INFO Channel 14/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gpua001:3089662:3089722 [0] NCCL INFO Channel 20/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gpua001:3089664:3089723 [2] NCCL INFO Channel 20/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gpua001:3089663:3089721 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gpua001:3089665:3089720 [3] NCCL INFO Channel 18/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gpua001:3089662:3089722 [0] NCCL INFO Channel 21/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gpua001:3089664:3089723 [2] NCCL INFO Channel 22/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gpua001:3089663:3089721 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gpua001:3089665:3089720 [3] NCCL INFO Channel 20/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gpua001:3089665:3089720 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
gpua001:3089664:3089723 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
gpua001:3089663:3089721 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
gpua001:3089662:3089722 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
Namespace(model='/work/hdd/bewo/mahdi/Isomorphic-Pruning/output/pruned/deit_4.2G_v2.pth', teacher_model='regnety_160.deit_in1k', data_path='/work/hdd/bewo/mahdi/imagenet', device='cuda', batch_size=256, epochs=300, workers=8, opt='adamw', lr=0.0005, momentum=0.9, weight_decay=0.05, norm_weight_decay=None, bias_weight_decay=None, transformer_embedding_decay=None, label_smoothing=0.1, mixup_alpha=0.8, cutmix_alpha=1.0, lr_scheduler='cosineannealinglr', lr_warmup_epochs=0, lr_warmup_method='linear', lr_warmup_decay=0.033, lr_step_size=30, lr_gamma=0.1, lr_min=0.0, print_freq=50, output_dir='/work/hdd/bewo/mahdi/Isomorphic-Pruning/output/finetuned/deit_4.2G_v2', resume='', start_epoch=0, cache_dataset=False, sync_bn=False, test_only=False, auto_augment='ra', ra_magnitude=9, augmix_severity=3, random_erase=0.25, color_jitter=None, amp=True, world_size=4, dist_url='env://', model_ema=False, model_ema_steps=32, model_ema_decay=0.99998, use_deterministic_algorithms=False, interpolation='bicubic', val_resize_size=256, val_crop_size=224, train_crop_size=224, clip_grad_norm=None, ra_sampler=True, ra_reps=3, weights=None, backend='pil', use_v2=False, is_huggingface=False, checkpoint_interval=10, no_imagenet_mean_std=False, stochastic_depth=0.0, rank=0, gpu=0, distributed=True, dist_backend='nccl')
Loading data
Loading training data
Took 2.7637150287628174
Loading validation data
Creating data loaders
Creating model
Loading pruned model from /work/hdd/bewo/mahdi/Isomorphic-Pruning/output/pruned/deit_4.2G_v2.pth
gpua001:3089664:3089831 [2] NCCL INFO misc/socket.cc:64 -> 3
gpua001:3089664:3089831 [2] NCCL INFO misc/socket.cc:80 -> 3
gpua001:3089664:3089831 [2] NCCL INFO misc/socket.cc:829 -> 3
gpua001:3089664:3089831 [2] NCCL INFO misc/socket.cc:64 -> 3
gpua001:3089664:3089831 [2] NCCL INFO misc/socket.cc:80 -> 3
gpua001:3089664:3089831 [2] NCCL INFO misc/socket.cc:829 -> 3
gpua001:3089664:3089831 [2] NCCL INFO misc/socket.cc:64 -> 3
gpua001:3089664:3089831 [2] NCCL INFO misc/socket.cc:80 -> 3
gpua001:3089664:3089831 [2] NCCL INFO misc/socket.cc:829 -> 3
gpua001:3089664:3089715 [2] NCCL INFO misc/socket.cc:881 -> 3
gpua001:3089664:3089831 [2] NCCL INFO misc/socket.cc:64 -> 3
gpua001:3089664:3089831 [2] NCCL INFO misc/socket.cc:80 -> 3
gpua001:3089664:3089831 [2] NCCL INFO misc/socket.cc:829 -> 3
gpua001:3089665:3089833 [3] NCCL INFO misc/socket.cc:64 -> 3
gpua001:3089665:3089833 [3] NCCL INFO misc/socket.cc:80 -> 3
gpua001:3089665:3089833 [3] NCCL INFO misc/socket.cc:829 -> 3
gpua001:3089665:3089833 [3] NCCL INFO misc/socket.cc:64 -> 3
gpua001:3089665:3089833 [3] NCCL INFO misc/socket.cc:80 -> 3
gpua001:3089665:3089833 [3] NCCL INFO misc/socket.cc:829 -> 3
gpua001:3089665:3089833 [3] NCCL INFO misc/socket.cc:64 -> 3
gpua001:3089665:3089833 [3] NCCL INFO misc/socket.cc:80 -> 3
gpua001:3089665:3089833 [3] NCCL INFO misc/socket.cc:829 -> 3
gpua001:3089665:3089833 [3] NCCL INFO misc/socket.cc:64 -> 3
gpua001:3089665:3089833 [3] NCCL INFO misc/socket.cc:80 -> 3
gpua001:3089665:3089833 [3] NCCL INFO misc/socket.cc:829 -> 3
gpua001:3089665:3089712 [3] NCCL INFO misc/socket.cc:881 -> 3
gpua001:3089664:3089715 [2] NCCL INFO misc/socket.cc:881 -> 3
gpua001:3089663:3089835 [1] NCCL INFO misc/socket.cc:64 -> 3
gpua001:3089663:3089835 [1] NCCL INFO misc/socket.cc:80 -> 3
gpua001:3089663:3089835 [1] NCCL INFO misc/socket.cc:829 -> 3
gpua001:3089663:3089835 [1] NCCL INFO misc/socket.cc:64 -> 3
gpua001:3089663:3089835 [1] NCCL INFO misc/socket.cc:80 -> 3
gpua001:3089663:3089835 [1] NCCL INFO misc/socket.cc:829 -> 3
gpua001:3089663:3089713 [1] NCCL INFO misc/socket.cc:881 -> 3
gpua001:3089663:3089835 [1] NCCL INFO misc/socket.cc:64 -> 3
gpua001:3089663:3089835 [1] NCCL INFO misc/socket.cc:80 -> 3
gpua001:3089663:3089835 [1] NCCL INFO misc/socket.cc:829 -> 3
gpua001:3089664:3089715 [2] NCCL INFO misc/socket.cc:881 -> 3
gpua001:3089663:3089835 [1] NCCL INFO misc/socket.cc:64 -> 3
gpua001:3089663:3089835 [1] NCCL INFO misc/socket.cc:80 -> 3
gpua001:3089663:3089835 [1] NCCL INFO misc/socket.cc:829 -> 3
gpua001:3089665:3089712 [3] NCCL INFO misc/socket.cc:881 -> 3
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33m_work_hdd_bewo_mahdi_Isomorphic-Pruning_output_pruned_deit_4.2G_v2.pth[0m at: [34mhttps://wandb.ai/saisoma239-iowa-state-university/Pruning/runs/hc9pwvvy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250711_070725-hc9pwvvy/logs[0m
gpua001:3089662:3089837 [0] NCCL INFO misc/socket.cc:64 -> 3
gpua001:3089662:3089837 [0] NCCL INFO misc/socket.cc:80 -> 3
gpua001:3089662:3089837 [0] NCCL INFO misc/socket.cc:829 -> 3
gpua001:3089662:3089714 [0] NCCL INFO misc/socket.cc:881 -> 3
gpua001:3089662:3089837 [0] NCCL INFO misc/socket.cc:64 -> 3
gpua001:3089662:3089837 [0] NCCL INFO misc/socket.cc:80 -> 3
gpua001:3089662:3089837 [0] NCCL INFO misc/socket.cc:829 -> 3
gpua001:3089663:3089713 [1] NCCL INFO misc/socket.cc:881 -> 3
gpua001:3089662:3089837 [0] NCCL INFO misc/socket.cc:64 -> 3
gpua001:3089662:3089837 [0] NCCL INFO misc/socket.cc:80 -> 3
gpua001:3089662:3089837 [0] NCCL INFO misc/socket.cc:829 -> 3
gpua001:3089664:3089715 [2] NCCL INFO misc/socket.cc:881 -> 3
gpua001:3089662:3089837 [0] NCCL INFO misc/socket.cc:64 -> 3
gpua001:3089662:3089837 [0] NCCL INFO misc/socket.cc:80 -> 3
gpua001:3089662:3089837 [0] NCCL INFO misc/socket.cc:829 -> 3
gpua001:3089665:3089712 [3] NCCL INFO misc/socket.cc:881 -> 3
gpua001:3089664:3089831 [2] NCCL INFO comm 0xb067340 rank 2 nranks 4 cudaDev 2 busId 85000 - Abort COMPLETE
gpua001:3089665:3089833 [3] NCCL INFO comm 0xae90c00 rank 3 nranks 4 cudaDev 3 busId c7000 - Abort COMPLETE
gpua001:3089663:3089835 [1] NCCL INFO comm 0xb12cfd0 rank 1 nranks 4 cudaDev 1 busId 46000 - Abort COMPLETE
